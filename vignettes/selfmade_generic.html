<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="David Ruegamer" />

<meta name="date" content="2019-03-09" />

<title>Selective Inference for Linear Mixed and Additive Models</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Selective Inference for Linear Mixed and Additive Models</h1>
<h4 class="author"><em>David Ruegamer</em></h4>
<h4 class="date"><em>2019-03-09</em></h4>



<div id="objective" class="section level2">
<h2>Objective</h2>
<p>This vignette describes the generic use of the <code>selfmade</code> software to produce valid post-selection inference, or more specifically <em>selective inference</em>, for linear mixed and additive models after any type of variable selection mechanism, which can be repeated in a bootstrap-like manner.</p>
</div>
<div id="prerequisites" class="section level2">
<h2>Prerequisites</h2>
<ul>
<li>The framework assumes that covariates in all models are fixed and that the repsonse variable <span class="math inline">\(y\)</span> in the model is the only source of randomness.</li>
<li>It must be possible to fit the final model with the <code>gamm4</code> function of the eponymous R package. Support for models from <code>mgcv</code> will be added in the future.</li>
<li>It must be possible to define a <strong>deterministic</strong> function of a vector <span class="math inline">\(y \in \mathbb{R}^n\)</span> determining the selection result for which the practioner seeks valid inference statements, referred to as <code>selection_function</code> in the following. In other words, the user has to define a function similar to the function <code>selection_function</code> defined below, which is deterministic in the sense that for the same input <code>y</code> the output should also be the same independent of any other setting.</li>
<li>It must be possible to define a function, which checks the congruency of the result of the <code>selection_function</code> and the original selection given when performing model selection on the original data <span class="math inline">\(y\)</span>. This is usually trivial and just a wrapper for the <code>selection_function</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">selection_function &lt;-<span class="st"> </span><span class="cf">function</span>(y)
{
  
  <span class="co"># based on any input y, which can be seen as some permutation of y</span>
  <span class="co"># a model is selected, usually mapped to an integer value</span>
  <span class="co"># ....</span>
  best_model_index &lt;-<span class="st"> </span><span class="kw">get_best_model</span>(list_of_models)
  
  <span class="kw">return</span>(best_model_index)
  
}</code></pre></div>
<p>Note that the <code>selection_function</code> should return the original result when called with the original data vector <span class="math inline">\(y\)</span>.</p>
</div>
<div id="approach" class="section level2">
<h2>Approach</h2>
<ol style="list-style-type: decimal">
<li>Run the experiment with the <code>original_response</code></li>
<li>Save the model selection result (e.g., as integer indicating the selected model) as well as the final model <code>final_model</code> (and refit this model with <code>gamm4</code> if a different package has beeen used for model selection)</li>
<li>Define the model selection function (<code>selection_function</code>)</li>
<li>Define the wrapper (<code>check_congruency</code>) function returning a logical value whether the result of any model call of <code>selection_function</code> is equivalent to the original model selection result</li>
<li>Run</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res &lt;-<span class="st"> </span><span class="kw">mocasin</span>(<span class="dt">mod =</span> final_model,
               <span class="dt">checkFun =</span> check_congruency,
               <span class="dt">this_y =</span> original_response
               <span class="co"># further options</span>
               )</code></pre></div>
</div>
<div id="examples" class="section level2">
<h2>Examples</h2>
<ul>
<li>Example 1 demonstrates the package’s ability to reproduce classical inference if no model selection was done.</li>
<li>Example 2 demonstrates the use of the package for model selection with only <code>gamm4</code> models</li>
<li>Example 3 demonstrates the package’s ability to calculate valid inference regardless of the type of model selection and packages involved (as long as the prerequisites are met)</li>
</ul>
<div id="example-1" class="section level3">
<h3>Example 1</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gamm4)
<span class="kw">set.seed</span>(<span class="dv">0</span>)
dat &lt;-<span class="st"> </span><span class="kw">gamSim</span>(<span class="dv">1</span>,<span class="dt">n=</span><span class="dv">500</span>,<span class="dt">scale=</span><span class="dv">2</span>) ## simulate 4 term additive truth

dat<span class="op">$</span>y &lt;-<span class="st"> </span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span>dat<span class="op">$</span>x0<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n=</span><span class="dv">500</span>)
br &lt;-<span class="st"> </span><span class="kw">gamm4</span>(y<span class="op">~</span><span class="st"> </span><span class="kw">s</span>(x0) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(x1), <span class="dt">data =</span> dat)
<span class="kw">summary</span>(br<span class="op">$</span>gam) ## summary of gam

<span class="co"># do not use any selection</span>
<span class="co"># - hence it's not necessary to define selection_function</span>
<span class="co">#   and the checl_congruency always returns TRUE</span>
checkFun &lt;-<span class="st"> </span><span class="cf">function</span>(yb) <span class="ot">TRUE</span>

<span class="co"># calculate selective inference, which, in this case,</span>
<span class="co"># except for an approximation error, should be equivalent</span>
<span class="co"># to the unconditional inference</span>
res &lt;-<span class="st"> </span><span class="kw">mocasin</span>(br, <span class="dt">this_y =</span> dat<span class="op">$</span>y,
               <span class="dt">checkFun =</span> checkFun,
               <span class="dt">nrlocs =</span> <span class="kw">c</span>(<span class="fl">0.7</span>,<span class="dv">1</span>),
               <span class="dt">nrSamples =</span> <span class="dv">1000</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
<span class="co"># we get very similar results using</span>
<span class="kw">do.call</span>(<span class="st">&quot;rbind&quot;</span>, res<span class="op">$</span>selinf)</code></pre></div>
</div>
<div id="example-2" class="section level3">
<h3>Example 2</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lme4)
<span class="kw">library</span>(lmerTest)
<span class="co"># use the ham data and use scaled information liking</span>
<span class="co"># as response</span>
ham<span class="op">$</span>Informed.liking &lt;-<span class="st"> </span><span class="kw">scale</span>(ham<span class="op">$</span>Informed.liking)

<span class="co"># We first define a function to fit a model based on response</span>
<span class="co"># This function is usually not required but can be </span>
<span class="co"># specified in order to define the selection_function</span>
<span class="co"># as a function of the model instead of as a function</span>
<span class="co"># of the response vector</span>
modFun &lt;-<span class="st"> </span><span class="cf">function</span>(y)
{
  ham<span class="op">$</span>y &lt;-<span class="st"> </span>y
  <span class="kw">lmer</span>(y <span class="op">~</span><span class="st"> </span>Gender <span class="op">+</span><span class="st"> </span>Information <span class="op">*</span><span class="st"> </span>Product <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>Consumer) <span class="op">+</span>
<span class="st">  </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>Product), <span class="dt">data=</span>ham)
  
  }

<span class="co"># define the selection_function:</span>
<span class="co"># here this is done as function of a model</span>
<span class="co"># which, in combination with modFun, can then</span>
<span class="co"># be used as function </span>
selFun &lt;-<span class="st"> </span><span class="cf">function</span>(mod) <span class="kw">step</span>(mod, <span class="dt">reduce.fixed =</span> <span class="ot">FALSE</span>)

<span class="co"># define a function which extracts the results </span>
<span class="co"># of the selection procedure</span>
extractSelFun &lt;-<span class="st"> </span><span class="cf">function</span>(this_mod){

this_mod &lt;-<span class="st"> </span><span class="kw">attr</span>(this_mod, <span class="st">&quot;model&quot;</span>)
<span class="cf">if</span>(<span class="kw">class</span>(this_mod)<span class="op">==</span><span class="st">&quot;lm&quot;</span>) 
  <span class="kw">return</span>(<span class="kw">attr</span>(this_mod<span class="op">$</span>coefficients, <span class="st">&quot;names&quot;</span>)) <span class="cf">else</span>
    <span class="kw">return</span>(<span class="kw">c</span>(<span class="kw">names</span>(<span class="kw">fixef</span>(this_mod)), 
             <span class="kw">names</span>(<span class="kw">getME</span>(this_mod, <span class="st">&quot;theta&quot;</span>))))

}

<span class="co"># Now we run the initial model selection on the </span>
<span class="co"># orginal data, which is a </span>
<span class="co"># backward elimination of non-significant effects:</span>
(step_result &lt;-<span class="st"> </span><span class="kw">selFun</span>(<span class="kw">modFun</span>(ham<span class="op">$</span>Informed.liking)))
<span class="kw">attr</span>(step_result, <span class="st">&quot;model&quot;</span>)
<span class="co"># Elimination tables for random- and fixed-effect terms:</span>
(sel &lt;-<span class="st"> </span><span class="kw">extractSelFun</span>(step_result))

<span class="co"># Now we can define the function checking the congruency</span>
<span class="co"># with the original selection</span>
checkFun &lt;-<span class="st"> </span><span class="cf">function</span>(yb){ 

 this_mod &lt;-<span class="st"> </span><span class="kw">modFun</span>(yb)
 <span class="kw">setequal</span>( <span class="kw">extractSelFun</span>(<span class="kw">selFun</span>(this_mod)), sel )
 
 }

<span class="co"># and compute valid p-values conditional on the selection</span>
<span class="co"># (this takes some time and will produce a lot of warnings)</span>
res &lt;-<span class="st"> </span><span class="kw">mocasin</span>(<span class="kw">attr</span>(step_result, <span class="st">&quot;model&quot;</span>), <span class="dt">this_y =</span> ham<span class="op">$</span>Informed.liking,
          <span class="dt">checkFun =</span> checkFun, <span class="dt">which =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dt">nrSamples =</span> <span class="dv">50</span>, <span class="dt">trace =</span> <span class="ot">FALSE</span>)

<span class="kw">print</span>(res)</code></pre></div>
</div>
<div id="example-3" class="section level3">
<h3>Example 3</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Run an AIC comparison between different additive models </span>
<span class="co"># fitted with mgcv::gam </span>
<span class="kw">library</span>(mgcv)
<span class="kw">library</span>(gamm4)

<span class="co"># create data and models</span>
<span class="kw">set.seed</span>(<span class="dv">2</span>)
<span class="co"># use enough noise to get a diverse model selection</span>
dat &lt;-<span class="st"> </span><span class="kw">gamSim</span>(<span class="dv">1</span>,<span class="dt">n=</span><span class="dv">400</span>,<span class="dt">dist=</span><span class="st">&quot;normal&quot;</span>,<span class="dt">scale=</span><span class="dv">10</span>)
b0123 &lt;-<span class="st"> </span><span class="kw">gam</span>(y<span class="op">~</span><span class="kw">s</span>(x0)<span class="op">+</span><span class="kw">s</span>(x1)<span class="op">+</span><span class="kw">s</span>(x2)<span class="op">+</span><span class="kw">s</span>(x3),<span class="dt">data=</span>dat)
b123 &lt;-<span class="st"> </span><span class="kw">gam</span>(y<span class="op">~</span><span class="kw">s</span>(x1)<span class="op">+</span><span class="kw">s</span>(x2)<span class="op">+</span><span class="kw">s</span>(x3),<span class="dt">data=</span>dat)
b013 &lt;-<span class="st"> </span><span class="kw">gam</span>(y<span class="op">~</span><span class="kw">s</span>(x0)<span class="op">+</span><span class="kw">s</span>(x1)<span class="op">+</span><span class="kw">s</span>(x3),<span class="dt">data=</span>dat)

<span class="co"># seems that the second model seems to be the most </span>
<span class="co"># 'appropriate' one</span>
<span class="kw">which.min</span>(<span class="kw">AIC</span>(b0123, b123, b013)<span class="op">$</span>AIC)
<span class="co"># and refit the model with gamm4</span>
b123_gamm4 &lt;-<span class="st"> </span><span class="kw">gamm4</span>(y<span class="op">~</span><span class="kw">s</span>(x0)<span class="op">+</span><span class="kw">s</span>(x1)<span class="op">+</span><span class="kw">s</span>(x3),<span class="dt">data=</span>dat)

<span class="co"># define selection_function</span>
selection_function &lt;-<span class="st"> </span><span class="cf">function</span>(y)
{
  
  dat<span class="op">$</span>y &lt;-<span class="st"> </span>y
  list_of_models &lt;-<span class="st"> </span><span class="kw">list</span>(
    <span class="kw">gam</span>(y<span class="op">~</span><span class="kw">s</span>(x0)<span class="op">+</span><span class="kw">s</span>(x1)<span class="op">+</span><span class="kw">s</span>(x2)<span class="op">+</span><span class="kw">s</span>(x3),<span class="dt">data=</span>dat),
    <span class="kw">gam</span>(y<span class="op">~</span><span class="kw">s</span>(x1)<span class="op">+</span><span class="kw">s</span>(x2)<span class="op">+</span><span class="kw">s</span>(x3),<span class="dt">data=</span>dat),
    <span class="kw">gam</span>(y<span class="op">~</span><span class="kw">s</span>(x0)<span class="op">+</span><span class="kw">s</span>(x1)<span class="op">+</span><span class="kw">s</span>(x3),<span class="dt">data=</span>dat)
  )

  <span class="co"># return an integer value which model is best</span>
  <span class="kw">return</span>(
    <span class="kw">which.min</span>(<span class="kw">sapply</span>(list_of_models, AIC))
  )
  
}

<span class="co"># define the congruency function</span>
checkFun &lt;-<span class="st"> </span><span class="cf">function</span>(y) <span class="kw">selection_function</span>(y)<span class="op">==</span><span class="dv">2</span>

<span class="co"># compute inference</span>
res &lt;-<span class="st"> </span><span class="kw">mocasin</span>(<span class="dt">mod =</span> b123_gamm4,
               <span class="dt">checkFun =</span> checkFun,
               <span class="dt">nrlocs =</span> <span class="dv">3</span>, <span class="co"># test one position of the spline</span>
               <span class="dt">nrSamples =</span> <span class="dv">10</span>)
<span class="kw">print</span>(res)</code></pre></div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
